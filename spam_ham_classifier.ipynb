{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udce7 SMS Spam Detection (Spam vs Ham)\n", "\n", "This notebook performs SMS spam detection using multiple features and models to ensure originality and low plagiarism. Dataset: UCI SMS Spam Collection."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 Imports\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import string\n", "import re\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk.stem import WordNetLemmatizer\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n", "nltk.download('punkt')\n", "nltk.download('wordnet')\n", "nltk.download('stopwords')\n", "nltk.download('averaged_perceptron_tagger')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce5 Load the Dataset\n", "\n", "You can download it from [UCI Repository](https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"SMSSpamCollection\", sep='\\t', names=['label', 'message'])\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d Feature Engineering"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Handcrafted features\n", "df['message_len'] = df['message'].apply(len)\n", "df['num_digits'] = df['message'].apply(lambda x: sum(char.isdigit() for char in x))\n", "df['num_uppercase'] = df['message'].apply(lambda x: sum(1 for c in x if c.isupper()))\n", "df['num_punctuation'] = df['message'].apply(lambda x: sum(1 for c in x if c in string.punctuation))\n", "df['num_words'] = df['message'].apply(lambda x: len(x.split()))\n", "\n", "# Text preprocessing\n", "stop_words = set(stopwords.words('english'))\n", "lemmatizer = WordNetLemmatizer()\n", "\n", "def clean_text(text):\n", "    text = text.lower()\n", "    text = re.sub(r'\\d+', '', text)\n", "    text = text.translate(str.maketrans('', '', string.punctuation))\n", "    tokens = nltk.word_tokenize(text)\n", "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n", "    return \" \".join(tokens)\n", "\n", "df['cleaned'] = df['message'].apply(clean_text)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# POS tag feature: Count nouns, verbs etc.\n", "def pos_counts(text):\n", "    tags = nltk.pos_tag(nltk.word_tokenize(text))\n", "    counts = nltk.FreqDist(tag for word, tag in tags)\n", "    return counts.get('NN', 0), counts.get('VB', 0), counts.get('JJ', 0)\n", "\n", "df[['noun_count', 'verb_count', 'adj_count']] = df['cleaned'].apply(\n", "    lambda x: pd.Series(pos_counts(x))\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd21 TF-IDF Vectorization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tfidf = TfidfVectorizer(max_features=3000)\n", "X_tfidf = tfidf.fit_transform(df['cleaned'])\n", "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Combine TF-IDF and handcrafted features\n", "features = pd.concat([\n", "    X_tfidf_df,\n", "    df[['message_len', 'num_digits', 'num_uppercase', 'num_punctuation', 'num_words', 'noun_count', 'verb_count', 'adj_count']]\n", "], axis=1)\n", "\n", "labels = df['label'].map({'ham': 0, 'spam': 1})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd16 Model Training & Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n", "\n", "models = {\n", "    'Naive Bayes': MultinomialNB(),\n", "    'Logistic Regression': LogisticRegression(max_iter=1000),\n", "    'Random Forest': RandomForestClassifier(n_estimators=100)\n", "}\n", "\n", "for name, model in models.items():\n", "    model.fit(X_train, y_train)\n", "    y_pred = model.predict(X_test)\n", "    print(f\"\\n{name} Results:\")\n", "    print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddf9 Data Cleaning and Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check for null values and duplicates\n", "print(\"Null values:\\n\", df.isnull().sum())\n", "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n", "\n", "# Drop duplicates if any\n", "df.drop_duplicates(inplace=True)\n", "df.reset_index(drop=True, inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcca Exploratory Data Analysis (EDA)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Distribution of spam vs ham\n", "sns.countplot(data=df, x='label')\n", "plt.title(\"Distribution of Spam and Ham Messages\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Message length distribution\n", "sns.histplot(data=df, x='message_len', hue='label', bins=50, kde=True)\n", "plt.title(\"Message Length Distribution\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Word count boxplot\n", "sns.boxplot(data=df, x='label', y='num_words')\n", "plt.title(\"Word Count by Message Type\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Correlation heatmap of numerical features\n", "numerics = ['message_len', 'num_digits', 'num_uppercase', 'num_punctuation', 'num_words', 'noun_count', 'verb_count', 'adj_count']\n", "plt.figure(figsize=(10, 6))\n", "sns.heatmap(df[numerics].corr(), annot=True, cmap='coolwarm')\n", "plt.title(\"Correlation Matrix of Handcrafted Features\")\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 2}